{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Mining: Resit Assignment Part 3Â¶\n",
    "\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Preprocessing vs Tuning (6 points (0.5+0.5+1+1+1+2))\n",
    "\n",
    "Consider the [Body fat dataset](http://www.openml.org/d/560). It contains a number of body measurements and the goal is to accurately predict bodyfat using only a few measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Analyze which are the most relevant features. Use a model-based feature selection technique based on GradientBoosting and plot the feature importance of all features. You can use the plotting code below to create the plot.\n",
    "- Split the data in a training and test set (the default split is fine), and apply the RandomForest-based technique to select and report the most relevant features. \n",
    "    - You can use the `SelectFromModel` method with the `median` threshold.\n",
    "    - Avoid data leaks: don't select features based on the test data.\n",
    "- Evaluate at least 4 regression algorithms, using default parameter settings, on the selected features and train-test split. Compare at least Decision Trees, Random Forests, Gaussian Processes, and SVMs (you can try several kernels). Report and interpret the R^2 scores.\n",
    "    - You can use the scikit-learn implementation of Gaussian processes (GPY is also allowed)\n",
    "- Explore the effect of the number of features by making the feature selection more strict (remove more features) The goal is to predict bodyfat using as few features as possible. What is the effect of using fewer features for each of your methods?\n",
    "    - For correct results, use a pipeline that includes at least a feature selection, normalization, and classifier step. Add more components if you think that they may help, but also discuss why and whether they helped.\n",
    "- Go back to your first selection of features (using the `median` threshold). Explore which models are overfitting by plotting the predictions. Do this for the most relevant feature (on the X-axis), and plot it against the target (Bodyfat, on the Y-axis). You can use the plotting code below, and adapt it to look at different parts of the X-axis. Interpret the plot: how well does each model perform? Does it match your earlier R^2 scores? Which algorithms are over/underfitting and may require more tuning?\n",
    "    - Don't include algorithms that received negative R^2 scores.\n",
    "    - Keep in mind that you are seeing only 1 feature while the model was trained on several more.\n",
    "- Optimize the main hyperparameters of the SVM and Gaussian Process algorithm. For SVM, you can stick to the RBF kernel. For Gaussian Processes, two kernels are given below. Don't forget to tune your regularization hyperparameters (C and alpha, both on a log scale, use at least 10 values). Use a grid search and plot the results in a heatmap (one for SVM, one for GPs). Interpret the results. Which values work best? Can you get much better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data \n",
    "fat_data = oml.datasets.get_dataset(560)\n",
    "X, y, attribute_names = fat_data.get_data(\n",
    "    target=fat_data.default_target_attribute, \n",
    "    return_attribute_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance plot. Input the training data, the attribute names (already given in the code above), \n",
    "# and the trained model\n",
    "def plot_feature_importances(data,attribute_names,model):\n",
    "    n_features = data.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), attribute_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the predictions of multiple models.\n",
    "# Property_index is the index of the most relevant feature (0 by default if feature selection was applied correctly)\n",
    "def plot_fat_predictions(X_train, X_test, y_train, y_test, models, property_index=0):\n",
    "    \n",
    "    X_all = np.concatenate((X_train, X_test),axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.rcParams['lines.linewidth'] = 1\n",
    "\n",
    "    prop = X_all[:,property_index]\n",
    "    prop_train = X_train[:,property_index]\n",
    "    prop_test = X_test[:,property_index]\n",
    "\n",
    "    sort_all = prop.argsort()\n",
    "    sort_train = prop_train.argsort()\n",
    "    sort_test = prop_test.argsort()\n",
    "\n",
    "    plt.scatter(prop_train[sort_train], y_train[sort_train], label=\"Training data\")\n",
    "    plt.scatter(prop_test[sort_test], y_test[sort_test], label=\"Test data\")\n",
    "    for name, model in models.items():\n",
    "        predictions = model.predict(X_all)\n",
    "        plt.plot(prop[sort_all], predictions[sort_all], label=name)\n",
    "    plt.xlabel(\"Property\")\n",
    "    plt.ylabel(\"Bodyfat\");\n",
    "    plt.legend()\n",
    "    #plt.xlim(1.04,1.06); # Zoom in on parts of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are two simple kernels for the Gaussian Process. \n",
    "# Feel free to adjust the parameters (e.g. the gamma parameter of the RBF kernel)\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "\n",
    "ker_rbf = RBF(0.1, length_scale_bounds=\"fixed\")\n",
    "ker_rbf2 = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(0.1, length_scale_bounds=\"fixed\")\n",
    "kernel_list = [ker_rbf, ker_rbf2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-validation, Out-of-bag error, Bias-Variance (4 points (1+1+2))\n",
    "RandomForests offer us an interesting, and cheaper, way to evaluate models instead of cross-validation: the out-of-bag error.\n",
    "It is often used to decide when to stop adding more trees to a forest.\n",
    "We will explore this on the [Wall Robot Navigation dataset](http://www.openml.org/d/1497), which contains \n",
    "about 5500 readings of an ultrasound sensor array mounted on a robot, and your task is to train a model\n",
    "to predict how the robot should move next.\n",
    "\n",
    "* First, train a RandomForest classifier on this dataset with an increasing number of trees (on a log scale to max. 512). Plot the Out-Of-Bag error against the number of trees. Which model would you build to control the robot? It should be as cheap as possible, and make predictions fast.\n",
    "    - The Out-Of-Bag error was discussed in the lecture on trees and ensembles. Example code is also added below.\n",
    "* Construct the same plot, but now use 10-fold Cross-validation and error rate instead of the OOB error. Compare the two. What can you deduce from this?\n",
    "* Compute the bias and variance for increasing numbers of trees. Does the bias and variance increase/decrease for the ensemble? Do these results somehow match your earlier observations? Explain in detail.\n",
    "\n",
    "Hint: Error rate = 1 - accuracy. It is not a standard scoring metric for ```cross_val_score```, so you'll need to let it compute the accuracy values, and then compute the mean error rate yourself.  \n",
    "Hint: We discussed bias-variance decomposition in class, and we have provided code to compute it earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = oml.datasets.get_dataset(1497) # Download Ionosphere data\n",
    "X, y = robot.get_data(target=eeg.default_target_attribute);\n",
    "\n",
    "# Out of bag errors can be retrieved from the RandomForest classifier as follows. \n",
    "# You'll need to loop over the number of trees yourself.\n",
    "# http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "(1 - clf.oob_score)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
