
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Regression with linear models &#8212; ML Engineering</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/banner.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">ML Engineering</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Overview
  </a>
 </li>
</ul>
    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/studies/S1 Regression with linear models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ml-course/master"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ml-course/master/issues/new?title=Issue%20on%20page%20%2Fstudies/S1 Regression with linear models.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ml-course/master/master?urlpath=tree/studies/S1 Regression with linear models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/ml-course/master/blob/master/studies/S1 Regression with linear models.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exploratory-analysis-and-visualization">
   Exploratory analysis and visualization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-linear-regression-models">
   Training linear regression models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-tuning">
   Hyperparameter tuning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-the-coefficients">
   Visualizing the coefficients
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Regression with linear models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exploratory-analysis-and-visualization">
   Exploratory analysis and visualization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-linear-regression-models">
   Training linear regression models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-tuning">
   Hyperparameter tuning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-the-coefficients">
   Visualizing the coefficients
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="regression-with-linear-models">
<h1>Regression with linear models<a class="headerlink" href="#regression-with-linear-models" title="Permalink to this headline">¶</a></h1>
<p>We explore the performance of several linear regression models on a real-world dataset, i.e. <a class="reference external" href="https://www.openml.org/d/41021">MoneyBall</a>. This dataset captures performance data from baseball players. The regression task is to accurately predict the number of ‘runs’ each player can score, and understanding which are the most important factors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># General imports</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">from</span> <span class="nn">preamble</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download MoneyBall data from OpenML</span>
<span class="n">moneyball</span> <span class="o">=</span> <span class="n">oml</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span><span class="mi">41021</span><span class="p">)</span>
<span class="c1"># Get the predictors X and the target y. Also get the list of categorical features for later use.</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">categorical</span><span class="p">,</span> <span class="n">attribute_names</span> <span class="o">=</span> <span class="n">moneyball</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">moneyball</span><span class="o">.</span><span class="n">default_target_attribute</span><span class="p">,</span> 
                                                        <span class="n">return_categorical_indicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                        <span class="n">return_attribute_names</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="exploratory-analysis-and-visualization">
<h2>Exploratory analysis and visualization<a class="headerlink" href="#exploratory-analysis-and-visualization" title="Permalink to this headline">¶</a></h2>
<p>First, we visually explore the data by visualizing the value distribution and the interaction between every other feature in a scatter matrix. We use the target feature as the color variable to see which features are correlated with the target.</p>
<p>For the plotting to work, however, we need to fill in the missing values. Let’s find out which columns have missing values. This matches what we already saw on the OpenML page (<a class="reference external" href="https://www.openml.org/d/41021">https://www.openml.org/d/41021</a>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Describe the data with pandas, just to get an overview</span>
<span class="n">ballframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">attribute_names</span><span class="p">)</span>
<span class="c1"># Ask pandas which columns have missing values</span>
<span class="n">pd</span><span class="o">.</span><span class="n">isnull</span><span class="p">(</span><span class="n">ballframe</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Team            False
League          False
Year            False
RA              False
W               False
OBP             False
SLG             False
BA              False
Playoffs        False
RankSeason       True
RankPlayoffs     True
G               False
OOBP             True
OSLG             True
dtype: bool
</pre></div>
</div>
</div>
</div>
<p>We impute the missing values using the median. This seems more adequate than replacing them by 0. Removing all instances with missing values is not really an option since some features have consistent missing values: we would have to remove a lot of data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Impute missing values with sklearn and rebuild the dataframe</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Imputer</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>
<span class="n">ballframe_clean</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ballframe</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">attribute_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we build the scatter matrix. We include the target column to see which features strongly correlate with the target, and also use the target value as the color to see which combinations of features correlate with the target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Scatter matrix of dataframe including the target feature</span>
<span class="n">copyframe</span> <span class="o">=</span> <span class="n">ballframe_clean</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 
<span class="n">copyframe</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">copyframe</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">copyframe</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">),</span> 
                  <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.8</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/S1 Regression with linear models_8_0.png" src="../_images/S1 Regression with linear models_8_0.png" />
</div>
</div>
<p>Several things immediately stand out:</p>
<ul class="simple">
<li><p>OBP, SLG and BA strongly correlate with the target (near-diagonals in the final column), but also combinations of either of these and W or R seem useful.</p></li>
<li><p>RA, W, OBP, SLG and B seem normally distributed, most others do not.</p></li>
<li><p>OOBP and OSLG have a very peaked distribution.</p></li>
<li><p>Several features (e.g. League, Playoffs,…) are clearly categorical and should be encoded before doing linear regression.</p></li>
</ul>
</div>
<div class="section" id="training-linear-regression-models">
<h2>Training linear regression models<a class="headerlink" href="#training-linear-regression-models" title="Permalink to this headline">¶</a></h2>
<p>To adequately build models, we need to:</p>
<ul class="simple">
<li><p>Impute missing values, e.g. by replacing NaN’s with the feature median</p></li>
<li><p>Encode categorical features, e.g. using OneHotEncoding</p></li>
</ul>
<p>We build a pipeline that does all these things in one go. We also explore the effect of scaling the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">ElasticNet</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Helper function to build and evaluate the pipelines</span>
<span class="c1"># Using MinMaxScaler because OneHotEncoding trips over negatively scaled values</span>
<span class="c1"># Another workaround would be panda&#39;s get_dummies method.</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;imp&quot;</span><span class="p">,</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)),</span> 
                     <span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">categorical_features</span><span class="o">=</span><span class="n">categorical</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)),</span>
                     <span class="p">(</span><span class="s2">&quot;reg&quot;</span><span class="p">,</span> <span class="n">regressor</span><span class="p">)])</span>
    <span class="k">if</span> <span class="n">scaling</span><span class="p">:</span>
        <span class="n">pipe</span><span class="o">.</span><span class="n">steps</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,[</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()])</span> 
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validated R^2 score for </span><span class="si">{}</span><span class="s2">: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">regressor</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Without scaler:&quot;</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">Ridge</span><span class="p">())</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">Lasso</span><span class="p">())</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">ElasticNet</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;With scaler:&quot;</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">(),</span> <span class="n">scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">Ridge</span><span class="p">(),</span> <span class="n">scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">Lasso</span><span class="p">(),</span> <span class="n">scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">ElasticNet</span><span class="p">(),</span> <span class="n">scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Without scaler:
Cross-validated R^2 score for LinearRegression: 0.85
Cross-validated R^2 score for Ridge: 0.76
Cross-validated R^2 score for Lasso: 0.83
Cross-validated R^2 score for ElasticNet: 0.83
With scaler:
Cross-validated R^2 score for LinearRegression: 0.91
Cross-validated R^2 score for Ridge: 0.83
Cross-validated R^2 score for Lasso: 0.90
Cross-validated R^2 score for ElasticNet: 0.05
</pre></div>
</div>
</div>
</div>
<p>Interestingly, LinearRegression is better than Ridge, and slightly better than Lasso. The latter two are perhaps overfitting and need to be tuned.</p>
<p>Scaling helps performance significantly, except for ElasticNet. Since scaling also changes the scale of the coefficients, the default hyperparameter settings may just fit better after scaling. Indeed, if one feature had a very different scale, the corresponding coefficient has to compensate for this, leading to possibly large coefficients and more likely overfitting. Thus, scaling may sometimes act as a regularizer. It is less clear why ElasticSearch performs so much worse, we should check what happens if we tune it.</p>
</div>
<div class="section" id="hyperparameter-tuning">
<h2>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">¶</a></h2>
<p>Next, we visualize the effect of the alpha regularizer for Ridge and Lasso, and both alpha and L1_ratio for ElasticNet</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span> 

<span class="n">grid_alpha</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">)}</span>

<span class="c1"># Build a pipeline and runs a grid search</span>
<span class="k">def</span> <span class="nf">evaluateGrid</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;imp&quot;</span><span class="p">,</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)),</span> 
                     <span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">categorical_features</span><span class="o">=</span><span class="n">categorical</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)),</span>
                     <span class="p">(</span><span class="s2">&quot;reg&quot;</span><span class="p">,</span> <span class="n">regressor</span><span class="p">)])</span>
    <span class="k">if</span> <span class="n">scaling</span><span class="p">:</span>
        <span class="n">pipe</span><span class="o">.</span><span class="n">steps</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,[</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()])</span> 
    <span class="k">return</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">ridge_res</span> <span class="o">=</span> <span class="n">evaluateGrid</span><span class="p">(</span><span class="n">Ridge</span><span class="p">(),</span> <span class="n">grid_alpha</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">ridge_res</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span> 
           <span class="n">ridge_res</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ridge&#39;</span><span class="p">)</span>
<span class="n">lasso_res</span> <span class="o">=</span> <span class="n">evaluateGrid</span><span class="p">(</span><span class="n">Lasso</span><span class="p">(),</span> <span class="n">grid_alpha</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">lasso_res</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span> 
           <span class="n">lasso_res</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Lasso&#39;</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best result </span><span class="si">{:.3f}</span><span class="s2"> with </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso_res</span><span class="o">.</span><span class="n">best_score_</span><span class="p">,</span> <span class="n">lasso_res</span><span class="o">.</span><span class="n">best_params_</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/S1 Regression with linear models_15_0.png" src="../_images/S1 Regression with linear models_15_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best result 0.926 with {&#39;reg__alpha&#39;: 0.071968567300115138}
</pre></div>
</div>
</div>
</div>
<p>Lasso (red line) find a better model than Ridge, with an optional alpha of around 0.1. For values larger than 1, it starts underfitting heavily (it penalizes large coefficients too much), and <span class="math notranslate nohighlight">\(R^2\)</span> drops to 0 (and lower). Ridge performs worse than Lasso overall, but is less sensitive to alpha and only starts overfitting heavily for alpha values of 100 or larger.</p>
<p>Next, we tune ElasticNet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run a 2D grid search and build a heatmap with the results</span>
<span class="n">grid_elastic_net</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span>
                    <span class="s1">&#39;reg__l1_ratio&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">5</span><span class="p">)}</span>
<span class="n">en_res</span> <span class="o">=</span> <span class="n">evaluateGrid</span><span class="p">(</span><span class="n">ElasticNet</span><span class="p">(),</span> <span class="n">grid_elastic_net</span><span class="p">)</span>

<span class="c1"># Reshape and transpose (we want alpha on the x-axes to compare with the previous plot)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">en_res</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
                                                       <span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__l1_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">],</span>
                      <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;L1 ratio&#39;</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__l1_ratio&#39;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/S1 Regression with linear models_17_0.png" src="../_images/S1 Regression with linear models_17_0.png" />
</div>
</div>
<p>For ElasticNet, the alpha hyperparameter clearly has the biggest impact on the accuracy. Similar to the previous plot, very small alpha values lesd to very slight overfitting, and very large values to disastrous underfitting. For alpha=0.1 and 1 we see a clear gradient favouring L1 loss: the lower the L1 ratio, the lower the performance.</p>
<p>We also see our previous findings confirmed:</p>
<ul class="simple">
<li><p>the best results are obtained by L1_ratio=1 (equal to Lasso) and alpha around 0.1 (see the previous curve)</p></li>
<li><p>the default ElasticNet (alpha=1,L1_ration=0.5) with standardisation performs badly, with <span class="math notranslate nohighlight">\(R^2=0.05\)</span> (see the previous table)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best configuration:&quot;</span><span class="p">,</span><span class="n">en_res</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best configuration: {&#39;reg__alpha&#39;: 0.10000000000000001, &#39;reg__l1_ratio&#39;: 1.0}
</pre></div>
</div>
</div>
</div>
<p>Out of curiosity, let’s now switch off the scaling. We get a similar heatmap, but ‘streched’ around alpha=0.1. The results of the ‘scaled’ alpha=0.01 are now (approximately) seen for alpha=0.0001 and the results of the ‘scaled’ alpha=0.1 are now seen around alpha=100. Hence, scaling made the models much more sensitive to alpha value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">en_res2</span> <span class="o">=</span> <span class="n">evaluateGrid</span><span class="p">(</span><span class="n">ElasticNet</span><span class="p">(),</span> <span class="n">grid_elastic_net</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Reshape and transpose (we want alpha on the x-axes to compare with the previous plot)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">en_res2</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
                                                <span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__l1_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__alpha&#39;</span><span class="p">],</span>
                      <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;L1 ratio&#39;</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">grid_elastic_net</span><span class="p">[</span><span class="s1">&#39;reg__l1_ratio&#39;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/S1 Regression with linear models_21_0.png" src="../_images/S1 Regression with linear models_21_0.png" />
</div>
</div>
</div>
<div class="section" id="visualizing-the-coefficients">
<h2>Visualizing the coefficients<a class="headerlink" href="#visualizing-the-coefficients" title="Permalink to this headline">¶</a></h2>
<p>Do the different models agree on which features are important? We also compare the results with the feature importances returned by a RandomForest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The OneHotEncoder has messed up our attribute names, so we must map features to names again</span>
<span class="c1"># feature_indices_ returns a mapping for the one-hot-encoded features</span>
<span class="n">fi</span> <span class="o">=</span> <span class="n">lasso_res</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;encoder&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">feature_indices_</span>
<span class="n">encoded_feats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">attribute_names</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">categorical</span><span class="p">)]</span>
<span class="n">non_encoded_feats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">attribute_names</span><span class="p">)[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">categorical</span><span class="p">)]</span>
<span class="n">new_names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">encoded_feats</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fi</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">fi</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
        <span class="n">new_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="n">j</span><span class="p">))</span>
<span class="n">new_names</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">non_encoded_feats</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We additionally train a RandomForest to see if it returns the same feature importances</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="n">rf_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;imp&quot;</span><span class="p">,</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)),</span>
                 <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()),</span> <span class="c1">#Adding scaler so that the OHE behaves the same</span>
                 <span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">categorical_features</span><span class="o">=</span><span class="n">categorical</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)),</span>
                 <span class="p">(</span><span class="s2">&quot;reg&quot;</span><span class="p">,</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">))])</span>
<span class="n">rf_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">max</span><span class="p">(</span><span class="n">rf_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">reg</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.75230929412401049
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;names&#39;</span><span class="p">:</span> <span class="n">new_names</span><span class="p">,</span> 
                   <span class="s1">&#39;lasso&#39;</span><span class="p">:</span> <span class="n">lasso_res</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;reg&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span>
                   <span class="s1">&#39;ridge&#39;</span><span class="p">:</span> <span class="n">ridge_res</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;reg&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span>
                   <span class="s1">&#39;elastic_net&#39;</span><span class="p">:</span> <span class="n">en_res</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;reg&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span>
                   <span class="s1">&#39;random_forest&#39;</span><span class="p">:</span> <span class="n">rf_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">reg</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">})</span>
<span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c1"># Coefficients</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">lasso</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Lasso&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">ind</span> <span class="o">+</span> <span class="n">width</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">ridge</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ridge&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">ind</span> <span class="o">+</span> <span class="n">width</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">elastic_net</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ElasticNet&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">new_names</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_names</span><span class="p">)))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Coefficients&#39;</span><span class="p">)</span>

<span class="c1"># RandomForest feature importances</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twiny</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">ind</span> <span class="o">+</span> <span class="n">width</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">random_forest</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;RandomForest&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature importance (RandomForest)&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.285</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span> <span class="c1">#</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/S1 Regression with linear models_26_0.png" src="../_images/S1 Regression with linear models_26_0.png" />
</div>
</div>
<p>The optimal models for elasticNet, ridge and lasso roughly agree on the importance of features. Especially SLG, OBP, W, and RA are deemed important, and to a lesser degree Year. OSLG, OOBP, and BA are deemed largely important.</p>
<p>One very obvious phenomenon is that Ridge considers all the one-hot-encoded features to be quite important. Since ridge uses the L2 norm, it will prefer many small coefficients, whereas Lasso (L1 norm) prefers to have many coefficients equal to 0. This is exactly what we are seeing here. From the plots above, we’ve seen that Ridge performs worse than Lasso, and the rather large coefficients for one-hot-encoded features hint at overfitting.</p>
<p>The optimal elasticnet had an L1_ratio=1, and will thus behave almost identical to Lasso.</p>
<p>RandomForest gives more or less similar results, although it deems W and RA much less important.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">We</span> <span class="n">can</span> <span class="n">also</span> <span class="n">estimate</span> <span class="n">feature</span> <span class="n">importance</span> <span class="k">with</span> <span class="n">a</span> <span class="n">RandomForest</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./studies"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joaquin Vanschoren<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>