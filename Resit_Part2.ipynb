{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Mining: Resit Assignment Part 2\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully convolutional neural networks (10 points)\n",
    "\n",
    "The goal of this excercise is to develop a model for recognizing seqences of MNIST digits in an image. You are given **one** image of size $(28, 28 \\times n)$ where $n$ is an integer. So, the input is a composition of $n$ MNIST images. The model needs to be able to recognize the sequence of digits that form the composition image. \n",
    "\n",
    "$n$ can take different values larger of 1. Training many different models for different values of $n$ is not very efficient. A more efficient strategy is to develop a model for detecting single digits and apply that model on the input image by sliding it (to cover the larger surface) and then post processing its output. Sliding a CNN model over a large image in the general case results in re-computing many of the computations. One approach that deals with this efficiently is converting the CNN model into a fully convolutional neural network(*).\n",
    "\n",
    "Any Dense layer can be converted to a Convolutional layer. For example, a Dense layer with K=128 neurons that inputs an activation map 7×7×512 can be equivalently expressed as a Convolutional layer with filter size of 7x7, (padding = 0, stride 1x1) and K=128 number of filters. Rather than flattening the activation map and feeding it into a dense layer we are using a Convolutional layer and setting the filter size to be exactly the size of the input volume (For more detais: https://arxiv.org/pdf/1411.4038.pdf).\n",
    "\n",
    "To solve this excercise extend/modify the code given bellow to:\n",
    "* Produce a CNN model for single digit detection of MNIST images\n",
    "* Convert this model into a fully convolutional neural network (FCNN)\n",
    "* Run the FCNN model on a image that is a composition of a sequence of MNIST images of length $n=5$\n",
    "* Post-process the FCNN output from the previous point to produce a numerical sequence of digits as output\n",
    "* Discuss how your implementation would need to be modified if the input is not a concatenation of MNIST image,s but rather the MNIST images are pasted on a random location on a large canvas (no implementatation is necessary)\n",
    "\n",
    "(*) FCNN models are very useful for processing very large images, such as produced in digital pathology or satelite imaging. This models are applicable to any domain where the size of the objects in the image is much smaller than the image itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "# Training parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# Data preparation\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_digits = 5\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "    input_shape_test = (1, img_rows, img_cols*num_digits)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    input_shape_test = (img_rows, img_cols * num_digits, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN Model definition\n",
    "def build_cnn_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # <<<<<<<<<<<<<<<<<<\n",
    "    # Add convolutional layers here to finalize the CNN model\n",
    "    # <<<<<<<<<<<<<<<<<<\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FCNN Model definition\n",
    "def build_full_conv_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # <<<<<<<<<<<<<<<<<<<\n",
    "    # Add convolutional layers here that match the CNN architecture\n",
    "    # <<<<<<<<<<<<<<<<<<<\n",
    "    \n",
    "    # This is are two example Conv layers that do the same operations \n",
    "    # as the Dense layers with 128 neurons and the final classification layer as given in the CNN model \n",
    "    # replace the <q> value of the size of the filters, such that it matches the dimension of the activation map\n",
    "    model.add(Conv2D(128, kernel_size=(<q>, <q>), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(num_classes, kernel_size=(1, 1)))\n",
    "    model.add(Reshape((-1, num_classes)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transplant_weight(weights_in, weights_out):\n",
    "    for layer in range(len(weights_in)):\n",
    "        weights_out[layer].flat = weights_in[layer].flat\n",
    "    return weights_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_concat_mnist(images, labels, size=100, length=5):\n",
    "    # form the appropriate tensor for the result\n",
    "    image_width = images.shape[2]\n",
    "    out = np.zeros((size, images.shape[1], image_width*length, images.shape[3]))\n",
    "    out_labels = np.zeros((size, length, labels.shape[1]))\n",
    "    # randomly sample images (size x length samples)\n",
    "    indexes = np.random.randint(0, images.shape[0], (size, length))\n",
    "    # fill in the final tensor for images and labels\n",
    "    for i in range(size):\n",
    "        for j in range(length):\n",
    "            start = image_width*j\n",
    "            end = image_width*(j+1)\n",
    "            out[i, :, start:end] = images[indexes[i, j]]\n",
    "            out_labels[i, j] = labels[indexes[i, j]]\n",
    "    return out, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build test data\n",
    "(x_concat_test, y_concat_test) = build_concat_mnist(x_test, y_test)\n",
    "\n",
    "# build models\n",
    "model = build_cnn_model()\n",
    "full_conv_model = build_full_conv_model()\n",
    "\n",
    "# model file\n",
    "model_file = \"mnist-model-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "# train\n",
    "model = train_cnn_model(model_file, model)\n",
    "# During testing you can load the CNN parameters, rather than train each time\n",
    "#model_load = \"mnist-model.hdf5\"\n",
    "#model.load_weights(model_load)\n",
    "\n",
    "model_weights = model.get_weights()\n",
    "\n",
    "full_conv_weights = full_conv_model.get_weights()\n",
    "full_conv_weights = transplant_weight(model_weights, full_conv_weights)\n",
    "full_conv_model.set_weights(full_conv_weights)\n",
    "\n",
    "# Execute the FCNN\n",
    "output = full_conv_model.predict(x_concat_test, batch_size=batch_size)\n",
    "# The output of the fully conv model needs to be processed to produce the sequence of digits\n",
    "output = np.argmax(output, axis=2)\n",
    "print(\"Model output\")\n",
    "\n",
    "# <<<<<<<<<<<<<<<\n",
    "# post processing the model output\n",
    "# <<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "# the true labels for comparison\n",
    "labels = np.argmax(y_concat_test, axis=2)\n",
    "print(\"Label outputs\")\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
