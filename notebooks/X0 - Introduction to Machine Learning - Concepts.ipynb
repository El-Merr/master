{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>html, body{overflow-y: visible !important} .CodeMirror{min-width:105% !important;} .rise-enabled .CodeMirror, .rise-enabled .output_subarea{font-size:140%; line-height:1.2; overflow: visible;} .output_subarea pre{width:110%}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global imports and settings\n",
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # Use 300 for PDF, 100 for slides\n",
    "HTML('''<style>html, body{overflow-y: visible !important} .CodeMirror{min-width:105% !important;} .rise-enabled .CodeMirror, .rise-enabled .output_subarea{font-size:140%; line-height:1.2; overflow: visible;} .output_subarea pre{width:110%}</style>''') # For slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Machine Learning\n",
    "## Concepts\n",
    "Joaquin Vanschoren, Eindhoven Univeristy of Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Artificial Intelligence\n",
    "1950s: Can computers be made to 'think'?\n",
    "- automate intellectual tasks normally performed by humans\n",
    "- encompasses learning, but also many other tasks (e.g. logic, planning,...)\n",
    "- _symbolic AI_: programmed rules/algorithms for manipulating knowledge\n",
    "    - Great for well-defined problems: chess, expert systems,...\n",
    "    - Pervasively used today (e.g. chip design)\n",
    "    - Hard for complex, fuzzy problems (e.g. images, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Machine Learning\n",
    "Are computers capable of learning and originality? Alan Turing: Yes!\n",
    "- Learn to perform a task T given experience E, always improving according to some metric M\n",
    "- New programming paradigm\n",
    "    - System is _trained_ rather than explictly programmed\n",
    "    - Finds rules or functions (models) to act/predict\n",
    "\n",
    "<img src=\"../images/00_ML.png\" alt=\"ml\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Machine learning vs Statistics\n",
    "* Both aim to make predictions of natural phenomena:\n",
    "<img src=\"../images/00_stat1.png\" alt=\"ml\" style=\"width: 200px;\"/>\n",
    "* Statistics:\n",
    "    - Help humans understand the world\n",
    "    - Parametric: assume that data is generated according to parametric model\n",
    "<img src=\"../images/00_stat2.png\" alt=\"ml\" style=\"width: 200px;\"/>\n",
    "* Machine learning:\n",
    "    - Automate a task entirely (replace the human)\n",
    "    - Non-parametric: assume that data generation process is unknown\n",
    "    - Engineering-oriented, less (too little?) mathematical theory\n",
    "<img src=\"../images/00_stat3.png\" alt=\"ml\" style=\"width: 200px;\"/>\n",
    "See Breiman (2001): Statical modelling: The two cultures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to represent learning?\n",
    "All machine learning algorithms consist of 3 components:\n",
    "- Representation: A model must be represented in a formal language that the computer can handle\n",
    "    - Defines the 'concepts' it can learn, the _hypothesis space-\n",
    "    - E.g. a decision tree, neural network, set of annotated data points\n",
    "- Evaluation: An _internal_ way to choose one hypothesis over the other\n",
    "    - Objective function, scoring/loss function\n",
    "    - E.g. Difference between correct output and predictions\n",
    "- Optimization: An _efficient_ way to search the hypothesis space\n",
    "    - Start from simple hypothesis, extend (relax) if it doesn't fit the data\n",
    "    - Defines speed of learning, number of optima,...\n",
    "    - E.g. Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to represent the problem?\n",
    "- We need 3 inputs:\n",
    "    - Input data, e.g. measurements, images, text\n",
    "    - Expected output: e.g. correct labels produced by humans\n",
    "    - Performance measure: feedback signal, are we learning the right thing?\n",
    "- Algorithm needs to correctly transform the inputs to the right outputs\n",
    "- Often includes transforming the data to a more useful representation (or encoding)\n",
    "    - Can be done end-to-end (e.g. deep learning) or by first 'preprocessing' the data\n",
    "<img src=\"../images/00_representation.png\" alt=\"ml\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deep Learning\n",
    "* Most machine learning techniques require humans to build a good representation of the data\n",
    "    * Sometimes data is naturally structured (e.g. medical tests)\n",
    "    * Sometimes not (e.g. images) -> extract features\n",
    "* Deep learning: learn your own representation of the data \n",
    "    * Through multiple layers of representation (e.g. layers of neurons)\n",
    "    * Each layer transforms the data a bit, based on what reduces the error\n",
    "<img src=\"../images/00_layers.png\" alt=\"ml\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example: digit classification\n",
    "- Input pixels go in, each layer transforms them to an increasingly informative representation for the given task\n",
    "- Often less intuitive for humans\n",
    "<img src=\"../images/00_layers2.png\" alt=\"ml\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Overview\n",
    "<img src=\"../images/00_AIvenn.png\" alt=\"ml\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Success stories:\n",
    "- Search engines (e.g. Google)\n",
    "- Recommender systems (e.g. Netflix)\n",
    "- Automatic translation (e.g. Google Translate)\n",
    "- Speech understanding (e.g. Siri, Alexa)\n",
    "- Game playing (e.g. AlphaGo)\n",
    "- Self-driving cars\n",
    "- Personalized medicine\n",
    "- Progress in all sciences: Genetics, astronomy, chemistry, neurology, physics,.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: dating\n",
    "<img src=\"../images/00_dating.png\" alt=\"ml\" style=\"width: 800px;\"/>\n",
    "- Is there a combination of factor that works? Is one better than others?\n",
    "- What can we assume about the future? Nothing?\n",
    "- What if there is noise / errors?\n",
    "- What if there are factor you don't know about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Types of machine learning\n",
    "We often distinguish 3 `types` of machine learning:\n",
    "\n",
    "- __Supervised Learning__: learn a model from labeled _training data_, then make predictions\n",
    "- __Unsupervised Learning__: explore the structure of the data to extract meaningful information\n",
    "- __Reinforcement Learning__: develop an agent that improves its performance based on interactions with the environment \n",
    "\n",
    "Note:\n",
    "\n",
    "- Semi-supervised methods combine the first two.\n",
    "- ML systems can combine many types in one system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Machine Learning\n",
    "\n",
    "- Learn a model from labeled training data, then make predictions\n",
    "- Supervised: we know the correct/desired outcome (label)\n",
    "\n",
    "2 subtypes:\n",
    "- Classification: predict a _class label_ (category), e.g. spam/not spam\n",
    "    - Many classifiers can also return a _confidence_ per class\n",
    "- Regression: predict a continuous value, e.g. temperature\n",
    "    - Some algorithms can return a _confidence interval_\n",
    "\n",
    "Most supervised algorithms that we will see can do both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![types](../images/01_supervised.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "- Class labels are discrete, unordered\n",
    "- Can be _binary_ (2 classes) or _multi-class_ (e.g. letter recognition)\n",
    "- Dataset can have any number of predictive variables (predictors)\n",
    "    - Also known as the dimensionality of the dataset\n",
    "- The predictions of the model yield a _decision boundary_ separating the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![classification](../images/01_classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression\n",
    "\n",
    "- Target variable is numeric\n",
    "- Find the relationship between predictors and the target.\n",
    "    - E.g. relationship between hours studied and final grade\n",
    "- Example: Linear regression (fits a straight line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![regression](../images/01_regression2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reinforcement learning\n",
    "\n",
    "- Develop an agent that improves its performance based on interactions with the environment\n",
    "    - Example: games like Chess, Go,...\n",
    "- _Reward function_ defines how well a (series of) actions works\n",
    "- Learn a series of actions that maximizes reward through exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![reinforcement learning](../images/01_rl2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsupervised Machine Learning\n",
    "\n",
    "- Unlabeled data, or data with unknown structure\n",
    "- Explore the structure of the data to extract information\n",
    "- Many types, we'll just discuss two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering\n",
    "\n",
    "- Organize information into meaningful subgroups (clusters)\n",
    "- Objects in cluster share certain degree of similarity (and dissimilarity to other clusters)\n",
    "- Example: distinguish different types of customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![clustering](../images/01_cluster2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dimensionality reduction\n",
    "\n",
    "- Data can be very high-dimensional and difficult to understand, learn from, store,...\n",
    "- Dimensionality reduction can compress the data into fewer dimensions, while retaining most of the information\n",
    "- Contrary to feature selection, the new features lose their (original) meaning\n",
    "- Is often useful for visualization (e.g. compress to 2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![dimred](../images/01_dimred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Terminology (on Iris dataset)\n",
    "![terminology](../images/01_terminology.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building machine learning systems\n",
    "A typical machine learning system has multiple components:\n",
    "    \n",
    "- Preprocessing: Raw data is rarely ideal for learning\n",
    "    - Feature scaling: bring values in same range\n",
    "    - Encoding: make categorical features numeric\n",
    "    - Discretization: make numeric features categorical\n",
    "    - Feature selection: remove uninteresting/correlated features\n",
    "    - Dimensionality reduction can also make data easier to learn\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Learning and model selection\n",
    "    - Every algorithm has its own biases\n",
    "    - No single algorithm is always best (No Free Lunch)\n",
    "    - _Model selection_ compares and selects the best models\n",
    "        - Different algorithms\n",
    "        - Every algorithm has different options (hyperparameters)\n",
    "    - Split data in training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Together they form a _workflow_ of _pipeline_\n",
    "\n",
    "![pipelines](../images/01_ml_systems.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_metadata": {
   "author": "Joaquin Vanschoren",
   "title": "Introduction"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
