{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEAM MEMBER 1 = ...  \n",
    "TEAM MEMBER 2 = ...  \n",
    "TEAM MEMBER 3 = ...  \n",
    "TEAM MEMBER 4 = ...  \n",
    "\n",
    "(Add a short description of what each team member contributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "* Answer the questions in this notebook, including the code, results, and explanations. For this assignment, however, it is NOT required to run everything in the notebook. You can run the experiments in separate Python scripts and include the results as images, as long as they match the code and explanations.\n",
    "* To create the PDF, see File > Download as. You can export to PDF via Latex, or export to HTML and then print to PDF.\n",
    "* Add a clear explanation of your approach and an in-depth interpretation of your results for every subquestion. Use markdown cells for this.\n",
    "* Keep the PDF below 20 pages. Remove these instructions and the general advise below in the final PDF.\n",
    "* Avoid all unnecessary outputs. Only output the answers to the questions. Add ';' behind lines that generate output to suppress the output.\n",
    "* Add the names of all team members below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General advice:\n",
    "* All tasks are to be completed using Keras, using the Sequential interface. \n",
    "* Training these models will take longer than you have been used to so far. Make sure to start computations well in advance of the deadline. Test your code on a small part of the data before training the model and especially for bugfixing. \n",
    "* While it should in principle be possible to reproduce all results via 'run all', it is NOT expected that you actually do this. Locally hosted notebooks are not ideal for long-running processes.\n",
    "* If you use plain python files for running the experiments, copy the relevant code into the notebook and also upload the complete python files to Blackboard.\n",
    "* Feel free to use any compute resources at your disposal. It should be possible to just use your CPU, but if possible, feel free to use your GPU. On [Google Colab](https://colab.research.google.com/) you can set up a notebook in the cloud [with GPU support](https://colab.research.google.com/notebooks/gpu.ipynb). There are many other options for hosted runtime environments, but sadly we can't offer support for using these.\n",
    "* When running locally, use the latest [TensorFlow installation instructions](https://www.tensorflow.org/install/). This typically offers better GPU support than the standard conda distribution. If you use a GPU, check whether TensorFlow is actually using it.  Use `sess =\n",
    "tf.Session(config=tf.ConfigProto(log_device_placement=True))` to start the tensorflow session to see which device is being used and confirm it is the device you intended.\n",
    "* You should NOT use k-fold cross-validation for any of these tasks. In each task, it is indicated how to split the data. Grid search is typically not practical for tuning your models, use a random search or a more focused approach to tune your models.\n",
    "* Always preprocess the images before training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Robots revisited (2 points)\n",
    "First, endow the [robot from the previous assignment](https://www.openml.org/d/1497) with a multilayer perceptron (feed forward neural network). You can scale all sensor data beforehand. Use two hidden layers and rectified linear nonlinearities. Use a stratified train/test split (holdout) with 1,000 examples in the test set. Include code for selecting L2 regularization strength (kernel_regularizer.l2, from 1e-3 to 1e3) and the number of hidden units in each layer using GridSearchCV or RandomSearchCV. Optimize on accuracy using the holdout above. Plot the results. Can you get better performance than the SVM from the previous assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fashion MNIST (2 points)\n",
    "Train a multilayer perceptron on the [Fashion MNIST dataset](https://www.openml.org/d/40996). Use at least two hidden layers and rectified linear nonlinearities.\n",
    "Use the traditional train/test split (first 60.000 instances for training, last 10.000 for testing). Set aside another 10000 samples (from the training set) using statified random sampling (e.g. use StratifiedShuffleSplit). This is meant for model selection and to compute learning curves. Compare a “vanilla” model with a model using drop-out. Visualize learning curves (accuracy vs epochs) for all models. As an estimate, you should expect each model to take less than 30 minutes to train on a CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Street view digits (3 points)\n",
    "The [Street View House Numbers](https://www.openml.org/d/41081) dataset contains cropped images of digits occuring in \n",
    "house numbers. Train a convolutional neural network to recognize the individual digits. You should achieve at least 85% test-set accuracy with a base model. Also build a model using batch normalization. Your final accuracy will be included in the grading. You can compare against [other submitted approaches](https://www.openml.org/t/168297) if you’re curious. On a CPU, each epoch (pass through the training set) can take up to ~40 minutes.\n",
    "\n",
    "Make sure you are doing the reshape for the training set correctly. A direct reshape might\n",
    "give you garbled images. Display an image after reshaping to make sure they are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cats vs Dogs (3 points)\n",
    "Load the weights of a pre-trained convolutional neural network included in Keras, see\n",
    "https://keras.io/applications/, and use it as feature extraction method to train a linear model (e.g. logistic regression) or multi-layer perceptron on the cats vs dogs dataset https://www.kaggle.com/c/dogs-vs-cats/data. You are working directly with images here, so there is a bit more preprocessing involved. It is recommended you store the extracted features on disk so you don’t have to recompute them for model selection.\n",
    "\n",
    "Hint: Make sure that you apply the same preprocessing to the images that was applied for\n",
    "training the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
